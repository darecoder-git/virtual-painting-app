# virtual-painting-app

I built a virtual painting model using a combination of OpenCV, Mediapipe, and a custom machine learning model that I trained on a dataset of hand gestures. The model was implemented in Python and used TensorFlow for the machine learning components. I used the hand tracking capabilities of Mediapipe to track the position of the user's hand in front of the camera, and I used the machine learning model to recognize different gestures and control the brush size, color, and other aspects of the painting. The user interface was built using PyQt, and it allowed the user to interact with the model and create their own virtual paintings. The model was trained on a dataset of over 10,000 hand gestures, and it achieved an accuracy of 95% on the test set.
